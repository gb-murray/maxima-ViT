# Configuration for training the ViT regression model on low-resolution images

paths:
  # Directory where the model checkpoint will be saved.
  output_dir: "../models/v1.0"

data:
  # Path to the HDF5 file containing the dataset.
  hdf5_path: "../datasets/MAXIMA-ViT_alpha_Al2O3_Eiger2Cdte_1M_k_dataset.hdf5"
  train_group: "training_pool"
  val_group: "test"

model:
  # Hugging Face name for the pre-trained Vision Transformer.
  backbone: "google/vit-base-patch16-224-in21k"
  vit_hidden_dim: 768 
  num_outputs: 6
  image_size: 224
  name: "MaxViT_v1.0f.pth"

training:
  freeze_backbone: false
  batch_size: 64
  epochs: 25
  learning_rate: 0.00001